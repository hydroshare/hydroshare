name: Get and Load django db snapshot into environment

on:
  workflow_dispatch:
    inputs:
      instance:
        description: 'Cluster and namespace to load the snapshot into'
        default: 'hydroshare-dev\dev-0'
        required: true
        type: choice
        options:
          - 'hydroshare-beta\default'
          - 'hydroshare-dev\dev-0'
          - 'hydroshare-dev\dev-1'
          - 'hydroshare-dev\dev-2'

      snapshot:
        description: 'The snapshot to load, default is latest or use the date of the snapshot file e.g 20250819 you want as the current format for the name is e.g backup-production-jjjjmmdd.sql'
        default: 'latest'
        required: true
        type: string
jobs:
  deploy:
    name: Run on ${{ inputs.instance }}
    runs-on: ubuntu-latest
    steps:
    - name: Extract cluster and namespace from instance input
      id: extract-cluster-info
      run: |
        INSTANCE="${{ inputs.instance }}"
        CLUSTER=$(echo "$INSTANCE" | awk -F'\\' '{print $1}')
        NAMESPACE=$(echo "$INSTANCE" | awk -F'\\' '{print $2}')
        echo "Extracted cluster: $CLUSTER"
        echo "Extracted namespace: $NAMESPACE"
        echo "cluster=$CLUSTER" >> $GITHUB_OUTPUT
        echo "namespace=$NAMESPACE" >> $GITHUB_OUTPUT

    - name: code checkout
      uses: actions/checkout@v3

    - uses: 'google-github-actions/auth@v2'
      with:
        credentials_json: ${{ secrets.HYDROSHARE_STORAGEREADER_KEY}}

    - name: Setup GKE credentials
      uses: google-github-actions/get-gke-credentials@v2
      with:
        cluster_name: ${{ steps.extract-cluster-info.outputs.cluster }}
        location: us-central1-a
        project_id: hydroshare-403701

    - name: Set Kubernetes context
      run: |
        echo "Setting context to cluster: ${{ steps.extract-cluster-info.outputs.cluster }} with namespace: ${{ steps.extract-cluster-info.outputs.namespace }}"
        kubectl config use-context gke_hydroshare-403701_us-central1-a_${{ steps.extract-cluster-info.outputs.cluster }}
        kubectl config set-context --current --namespace=${{ steps.extract-cluster-info.outputs.namespace }}

    - name: Load django db into environment
      run: |
        # Get the current kubectl context
        CURRENT_CONTEXT=$(kubectl config current-context)
        echo "Current kubectl context: $CURRENT_CONTEXT"
        
        NAMESPACE="${{ steps.extract-cluster-info.outputs.namespace }}"
        CLUSTER="${{ steps.extract-cluster-info.outputs.cluster }}"
        echo "Using cluster: $CLUSTER"
        echo "Using namespace: $NAMESPACE"
                     
        # Retrieves the name of the first Kubernetes pod labeled with 'app=postgis' and stores it in the POSTGIS_POD variable.  
        POSTGIS_POD=$(kubectl get pods -l app=postgis -n $NAMESPACE -o jsonpath="{.items[0].metadata.name}")
        echo "postgis pod name: $POSTGIS_POD"        
        PGBOUNCER_POD=$(kubectl get pods -l app=pgbouncer -n $NAMESPACE -o jsonpath="{.items[0].metadata.name}")
        echo "PG_bouncer pod name: $PGBOUNCER_POD"
        
                 
        # Retrieves the most recently modified file from the specified Google Cloud Storage bucket by
        # listing all files recursively, sorting them, and selecting the last entry.
        BUCKET_NAME="hydroshare-postgis-dumps"
        echo "Finding backup in bucket: $BUCKET_NAME"
        if [ "${{ inputs.snapshot }}" = "latest" ]; then
          echo "Getting latest"
          LATEST_FILE=$(gcloud storage ls --recursive gs://$BUCKET_NAME/** | sort | tail -n 1)
        else
          # Try to find a file matching the provided snapshot date or name
          echo "Finding backup matching '${{ inputs.snapshot }}'"
          LATEST_FILE=$(gcloud storage ls --recursive gs://$BUCKET_NAME/** | grep "${{ inputs.snapshot }}" | sort | tail -n 1)
          if [ -z "$LATEST_FILE" ]; then
            echo "No snapshot found matching '${{ inputs.snapshot }}'"
            exit 1
          fi
        fi
        echo "Latest file: $LATEST_FILE"

        # This step generates a signed URL for the latest file in Google Cloud Storage.
        # It uses the `gcloud storage sign-url` command with a specified service account for impersonation,
        # and sets the URL to be valid for 1 hour. The resulting signed URL is extracted from the command output.
        SIGNED_URL=$(gcloud storage sign-url --impersonate-service-account=hydroshare-storagereader@hydroshare-403701.iam.gserviceaccount.com --duration=1h "$LATEST_FILE" | awk -F' ' '{print $2}')

        # Extracts the fourth field from the SIGNED_URL variable (assuming it contains space-separated values)
        # and assigns it back to SIGNED_URL. This is typically used to isolate a specific part of a command output.
        SIGNED_URL=$(echo $SIGNED_URL | awk -F' ' '{print $4}')
        echo $SIGNED_URL
                  
        
        # The following commands scale down the specified Kubernetes statefulsets to zero replicas,
        # effectively stopping the associated pods. This is often done to ensure that no active connections
        # are present while performing database operations.
        # This is important for maintaining data integrity during the database snapshot loading process.

        DEFAULTWORKER_REPLICAS=$(kubectl get statefulset defaultworker-worker -n $NAMESPACE -o jsonpath="{.spec.replicas}")
        echo "defaultworker replicas before scale down: $DEFAULTWORKER_REPLICAS"

        HYDROSHARE_REPLICAS=$(kubectl get statefulset hydroshare -n $NAMESPACE -o jsonpath="{.spec.replicas}")        
        echo "hydroshare replicas before scale down: $HYDROSHARE_REPLICAS"
        
        # Scale down statefulsets to 0 replicas
        kubectl scale $(kubectl get statefulset -o name | grep defaultworker) --replicas=0
        kubectl scale $(kubectl get statefulset -o name | grep hydroshare) --replicas=0
        
        kubectl delete pod $POSTGIS_POD 
        # Wait for the old pod to terminate before refreshing pod name
        kubectl wait --for=delete pod/$POSTGIS_POD -n $NAMESPACE --timeout=60s
        # refresh postgis pod name after restart
        POSTGIS_POD=$(kubectl get pods -l app=postgis -n $NAMESPACE -o jsonpath="{.items[0].metadata.name}")
        echo "new postgis pod: $POSTGIS_POD"
        if [ -n "$PGBOUNCER_POD" ]; then
          kubectl delete pod $PGBOUNCER_POD -n $NAMESPACE
        else
          echo "No pgbouncer pod found to delete."
        fi
        echo "Waiting for postgis pod to be ready after restart"
        kubectl wait --for=condition=ready pod/$POSTGIS_POD -n $NAMESPACE --timeout=120s
        kubectl exec -n $NAMESPACE $POSTGIS_POD -- bash -c 'until pg_isready -U postgres; do sleep 5; done'
        echo "postgres is ready"
               
        # Installs the 'wget' utility inside the specified PostGIS pod using apt-get.
        # This is useful for downloading files directly within the pod during workflow execution.
        kubectl exec $POSTGIS_POD -- apt-get update
        kubectl exec $POSTGIS_POD -- apt-get install -y wget
        kubectl exec $POSTGIS_POD -- mkdir -p /tmp/01
        
        echo "downloading snapshot"
        
        kubectl exec $POSTGIS_POD -- wget -O /tmp/01/pg.development.sql --no-verbose  "$SIGNED_URL"
        
        kubectl exec $POSTGIS_POD -- test -s /tmp/01/pg.development.sql

        kubectl exec $POSTGIS_POD -- psql -U postgres -c "REVOKE CONNECT ON DATABASE postgres FROM public;"
        echo "Terminating existing connections in postgis pod: $POSTGIS_POD"
        
        kubectl exec $POSTGIS_POD -- psql -U postgres -c "SELECT pid, pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = current_database() AND pid <> pg_backend_pid();"
        echo "Dropping and creating postgres database in postgis pod: $POSTGIS_POD"
        kubectl exec $POSTGIS_POD -- dropdb -U postgres -h localhost postgres

        echo "Creating postgres database in postgis pod: $POSTGIS_POD"
        kubectl exec $POSTGIS_POD -- createdb -U postgres -h localhost postgres
        echo "Copying SQL files to /docker-entrypoint-initdb.d in postgis pod: $POSTGIS_POD"
        echo "Running init-db.sh in postgis pod: $POSTGIS_POD"
          
        kubectl exec $POSTGIS_POD -- psql -U postgres -d hydroshare -f /init/00/init.sql
        kubectl exec $POSTGIS_POD -- psql -U postgres -d postgres -f /tmp/01/pg.development.sql

        # The following commands scale the specified Kubernetes statefulsets back to their original number of replicas,
        # effectively restarting the associated pods. This is done after completing database operations to restore
        # normal application functionality.
        kubectl scale $(kubectl get statefulset -o name | grep defaultworker) --replicas=$DEFAULTWORKER_REPLICAS
        kubectl scale $(kubectl get statefulset -o name | grep hydroshare) --replicas=$HYDROSHARE_REPLICAS
        
        
        # Restart the container in the postgis pod
        echo "Restarting postgis pod: $POSTGIS_POD"
        kubectl delete pod $POSTGIS_POD -n $NAMESPACE
        kubectl wait --for=delete pod/$POSTGIS_POD -n $NAMESPACE --timeout=120s
        POSTGIS_POD=$(kubectl get pods -l app=postgis -n $NAMESPACE -o jsonpath="{.items[0].metadata.name}")
        echo "Waiting for postgis pod to restart"
        kubectl wait --for=condition=ready pod/$POSTGIS_POD -n $NAMESPACE --timeout=180s
        HYDROSHARE_POD=$(kubectl get pods -n $NAMESPACE -l app=hydroshare -o jsonpath="{.items[0].metadata.name}")
        echo "Hydroshare pod: $HYDROSHARE_POD"
        echo "wait for pod to spin up"
        kubectl wait --for=condition=ready pod/$HYDROSHARE_POD -n $NAMESPACE --timeout=180s
        echo "Running solr_update in Hydroshare pod: $HYDROSHARE_POD"
        kubectl exec -n $NAMESPACE $HYDROSHARE_POD -- python manage.py solr_update
        echo "Database snapshot load and solr update completed successfully."